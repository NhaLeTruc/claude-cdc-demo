# Spark Configuration for CDC Demo with Delta Lake
# Delta Lake Extensions
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# Delta Lake JAR Package (updated to 3.3.2 for CDF support)
spark.jars.packages=io.delta:delta-spark_2.12:3.3.2,org.apache.hadoop:hadoop-aws:3.3.4

# Enable Change Data Feed (CDF) by default
spark.databricks.delta.properties.defaults.enableChangeDataFeed=true

# S3A Configuration for MinIO
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=minioadmin
spark.hadoop.fs.s3a.secret.key=minioadmin
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# Warehouse Directory (S3A path for Delta tables)
spark.sql.warehouse.dir=s3a://warehouse/

# Disable Event Logging (not needed for testing)
spark.eventLog.enabled=false

# Executor Configuration
spark.executor.instances=1
spark.executor.cores=1
spark.executor.memory=1g

# Driver Configuration
spark.driver.memory=1g
spark.driver.cores=1

# Network Timeout (increase for stability)
spark.network.timeout=300s

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer

# UI Configuration
spark.ui.port=4040
spark.ui.reverseProxy=false
